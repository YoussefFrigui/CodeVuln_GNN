# Complete Pipeline Workflow

## Visual Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚                    GNN VULNERABILITY DETECTION PIPELINE                    â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


STEP 0: FILTER ADVISORIES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ data/advisory-database/advisories/github-reviewed/**/*.json
                                â”‚
                                â”‚ (Scan ~28k JSON files)
                                â–¼
                    src/filter_python_advisories.py
                                â”‚
                                â”‚ (Filter: ecosystem == "PyPI")
                                â–¼
ğŸ“„ outputs/datasets/python_advisories.json (~3,900 advisories)
   {
     "id": "GHSA-xxxx-yyyy-zzzz",
     "summary": "SQL injection...",
     "severity": "HIGH",
     "references": [{"url": "https://github.com/..."}]
   }


STEP 1: EXTRACT VULNERABLE CODE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“„ outputs/datasets/python_advisories.json
                                â”‚
                                â”‚ (Extract commit URLs)
                                â–¼
                scripts/00_preprocess_advisories.py
                                â”‚
                                â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ â”‚ GitHub API Fetching  â”‚
                                â”‚ â”‚ â€¢ Rate limiting      â”‚
                                â”‚ â”‚ â€¢ Retry logic        â”‚
                                â”‚ â”‚ â€¢ Progress tracking  â”‚
                                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                        Commit Data (JSON)
                                â”‚
                                â”‚ (Parse git diffs)
                                â”‚ - Lines = vulnerable code
                                â”‚ + Lines = fixed code
                                â–¼
ğŸ“„ outputs/datasets/processed_advisories_with_code.json (~1,800 examples)
   {
     "advisory_id": "GHSA-xxxx-yyyy-zzzz",
     "vulnerable_code": "query = 'SELECT * FROM...'",
     "fixed_code": "query = 'SELECT * FROM WHERE id=?'",
     "filename": "models/sql.py"
   }


STEP 2: CREATE GRAPH DATASET
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VULNERABLE CODE                      â”‚  â”‚ SAFE CODE                        â”‚
â”‚                                      â”‚  â”‚                                  â”‚
â”‚ processed_advisories_with_code.json  â”‚  â”‚ data/python/.../train/*.jsonl    â”‚
â”‚ (~1,800 examples)                    â”‚  â”‚ (CodeSearchNet: 200k examples)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                     src/create_dataset.py
                                     â”‚
                                     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚ â”‚ Code â†’ Graph        â”‚
                                     â”‚ â”‚                     â”‚
                                     â”‚ â”‚ 1. ast.parse()      â”‚
                                     â”‚ â”‚ 2. AST â†’ NetworkX   â”‚
                                     â”‚ â”‚ 3. NetworkX â†’ PyG   â”‚
                                     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
ğŸ“¦ outputs/datasets/final_graph_dataset.pt
   PyTorch Geometric Dataset (200k+ graphs)
   
   Graph Structure:
   â€¢ Nodes: AST elements (FunctionDef, Call, If, etc.)
   â€¢ Edges: Parent-child relationships
   â€¢ Features: 11-dim node type embeddings
   â€¢ Labels: 0 (safe) or 1 (vulnerable)


STEP 3: TRAIN GNN MODEL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¦ final_graph_dataset.pt
                    â”‚
                    â”‚ (Load & split: 80/10/10)
                    â–¼
        scripts/02_train_model.py
                    â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ â”‚ GNN Architecture           â”‚
                    â”‚ â”‚ â€¢ 4x GCN layers            â”‚
                    â”‚ â”‚ â€¢ GAT attention layer      â”‚
                    â”‚ â”‚ â€¢ Global mean pooling      â”‚
                    â”‚ â”‚ â€¢ MLP classifier           â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ â”‚ Training Loop              â”‚
                    â”‚ â”‚ â€¢ Weighted cross-entropy   â”‚
                    â”‚ â”‚ â€¢ Early stopping           â”‚
                    â”‚ â”‚ â€¢ MLflow tracking          â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                      â”‚
                    â–¼                                      â–¼
ğŸ§  outputs/models/                              ğŸ“Š outputs/mlruns/
   trained_gnn_model.pt                            <experiment_id>/
   (Trained model weights)                         â”œâ”€â”€ metrics/
                                                   â”œâ”€â”€ params/
                                                   â”œâ”€â”€ artifacts/
                                                   â””â”€â”€ model/


STEP 4: EVALUATION & TRACKING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š outputs/mlruns/
        â”‚
        â”‚ (Launch UI)
        â–¼
python view_mlflow.py
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MLflow UI (http://localhost:5000)                                 â”‚
â”‚                                                                    â”‚
â”‚ Experiments:                                                       â”‚
â”‚ â”œâ”€â”€ Run 1: baseline (accuracy: 0.992, F1: 0.843)                  â”‚
â”‚ â”œâ”€â”€ Run 2: larger_hidden (accuracy: 0.994, F1: 0.867)             â”‚
â”‚ â””â”€â”€ Run 3: more_layers (accuracy: 0.995, F1: 0.891)               â”‚
â”‚                                                                    â”‚
â”‚ Metrics Charts:                                                    â”‚
â”‚ â€¢ Training/Validation Loss                                         â”‚
â”‚ â€¢ Accuracy, Precision, Recall, F1                                  â”‚
â”‚ â€¢ Per-class performance                                            â”‚
â”‚                                                                    â”‚
â”‚ Model Registry:                                                    â”‚
â”‚ â””â”€â”€ VulnerabilityGNN (version 3) - Production                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow Summary

```
Raw JSON Files â†’ Python Advisories â†’ Vulnerable Code â†’ Graph Dataset â†’ Trained Model
  (28k files)      (3.9k advisories)    (1.8k examples)   (200k graphs)    (GNN)
     ~500MB            ~2MB                 ~15MB            ~1.2GB         ~5MB
```

## Key Metrics at Each Stage

| Stage | Input Count | Output Count | Filtering Reason |
|-------|-------------|--------------|------------------|
| Filter Advisories | 28,000 | 3,900 | Only PyPI ecosystem |
| Extract Vulnerable Code | 3,900 | 1,800 | Only with commit URLs + Python code |
| Create Graphs | 201,800 | 196,400 | Syntax errors, malformed code |
| Training | 196,400 | 196,400 | No filtering (all used) |

## Class Distribution

```
Vulnerable Examples (label=1):    1,800 (0.92%)  â–ˆâ–ˆâ–ˆâ–ˆ
Safe Examples (label=0):        194,600 (99.08%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Class Imbalance Ratio: 1:108

Solution: Weighted Cross-Entropy Loss
  â€¢ Safe class weight:       ~0.5
  â€¢ Vulnerable class weight: ~54.0
```

## Processing Time Breakdown

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step                    â”‚ Duration  â”‚ Bottleneck              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Filter advisories       â”‚ 30 sec    â”‚ I/O (file scanning)     â”‚
â”‚ Extract vulnerable code â”‚ 15 min    â”‚ Network (GitHub API)    â”‚
â”‚ Create dataset          â”‚ 15 min    â”‚ CPU (AST parsing)       â”‚
â”‚ Train model (GPU)       â”‚ 30 min    â”‚ GPU (graph convolutions)â”‚
â”‚ Train model (CPU)       â”‚ 2 hours   â”‚ CPU (slow conv ops)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL (GPU)             â”‚ ~1 hour   â”‚                         â”‚
â”‚ TOTAL (CPU)             â”‚ ~2.5 hoursâ”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dependencies Between Steps

```
Step 0 (Filter) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚
                              â–¼
Step 1 (Extract Code) â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚
                              â–¼
Step 2 (Create Dataset) â”€â”€â”€â”€â”€â”€â”
                              â”‚
                              â–¼
Step 3 (Train Model) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚
                              â–¼
                        âœ… Trained Model
```

**Cannot skip steps:** Each step depends on output from previous step.

**Can re-run independently:** Once a step completes, its output file is cached.
- Example: After Step 2, can run Step 3 multiple times with different hyperparameters
- Example: After Step 1, can run Step 2 with different `max_safe_examples`

## Configuration-Driven Approach

All steps read from `configs/base_config.yaml`:

```yaml
data:
  advisories_path: "outputs/datasets/processed_advisories_with_code.json"
  codesearchnet_dir: "data/python/python/final/jsonl/train"
  processed_dataset_path: "outputs/datasets/final_graph_dataset.pt"

dataset:
  max_safe_examples: 200000
  max_nodes_per_graph: 100

model:
  hidden_channels: 128
  gcn_layers: 4
  gat_heads: 8
  dropout: 0.3

training:
  num_epochs: 20
  batch_size: 64
  learning_rate: 0.001
  patience: 5
```

**Benefit:** Change parameters without editing code. MLflow tracks all config values.

## Progress Tracking

Every long-running operation shows tqdm progress:

```
Step 0: Scanning advisory files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28143/28143 [00:28<00:00]
Step 1: Fetching commits: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2847/2847 [15:23<00:00]
Step 2: Converting to graphs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201897/201897 [12:34<00:00]
Step 3: Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3141/3141 [02:34<00:00] loss: 0.234
```

**Real-time metrics:**
- Items processed / Total items
- Time elapsed / Time remaining
- Processing rate (items/sec)
- Current loss/accuracy (training)
